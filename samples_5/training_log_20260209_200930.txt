================================================================================
TRAINING LOG
================================================================================
Start Time: 2026-02-09 20:09:31

CONFIGURATION:
--------------------------------------------------------------------------------
image_size               : 256
batch_size               : 4
num_epochs               : 100
lr_g                     : 0.0002
lr_d                     : 0.0002
beta1                    : 0.5
beta2                    : 0.999
lambda_contrastive       : 1.0
lambda_identity          : 5.0
lambda_saturation        : 2.0
target_saturation        : 0.7
temperature              : 0.07
save_interval            : 10
checkpoint_dir           : checkpoints_5
sample_dir               : samples_5

MODEL ARCHITECTURE:
--------------------------------------------------------------------------------
Generator parameters:     5,846,723
Discriminator parameters: 433,267

LOSS FUNCTIONS:
--------------------------------------------------------------------------------
- GAN Loss: MSE (LSGAN)
- Contrastive Loss: InfoNCE
- Identity Loss: L1
- Saturation Loss: DISABLED (commented out)

================================================================================
EPOCH RESULTS:
================================================================================
 Epoch |   D_loss |   G_loss |      GAN | Contrast
--------------------------------------------------------------------------------
     1 |   0.2122 |   3.5013 |   0.4325 |   1.5204
     2 |   0.1775 |   3.5137 |   0.5325 |   1.5262
     3 |   0.1777 |   3.4695 |   0.5262 |   1.5393
     4 |   0.1766 |   3.4660 |   0.5284 |   1.5669
     5 |   0.1708 |   3.4346 |   0.5419 |   1.5674
     6 |   0.1646 |   3.4282 |   0.5653 |   1.5784
     7 |   0.1576 |   3.4137 |   0.5800 |   1.5789
     8 |   0.1607 |   3.4162 |   0.5793 |   1.5805
     9 |   0.1611 |   3.3807 |   0.5624 |   1.5902
    10 |   0.1676 |   3.3645 |   0.5530 |   1.5871
    11 |   0.1657 |   3.3705 |   0.5564 |   1.5880
    12 |   0.1646 |   3.3803 |   0.5637 |   1.5905
    13 |   0.1654 |   3.3620 |   0.5549 |   1.5947
    14 |   0.1607 |   3.3896 |   0.5820 |   1.6004
    15 |   0.1509 |   3.4127 |   0.6167 |   1.5976
    16 |   0.1455 |   3.4445 |   0.6529 |   1.5923
    17 |   0.1402 |   3.5003 |   0.6878 |   1.6010
    18 |   0.1350 |   3.5109 |   0.7099 |   1.5925
    19 |   0.1300 |   3.5611 |   0.7344 |   1.6017
    20 |   0.1192 |   3.6282 |   0.7759 |   1.6047
    21 |   0.1227 |   3.5621 |   0.7468 |   1.6012
    22 |   0.1210 |   3.5879 |   0.7647 |   1.5949
    23 |   0.1170 |   3.5956 |   0.7655 |   1.5988
    24 |   0.1170 |   3.6064 |   0.7801 |   1.5981
    25 |   0.1186 |   3.6104 |   0.7773 |   1.6030
    26 |   0.1081 |   3.6500 |   0.8134 |   1.5944
    27 |   0.1090 |   3.6510 |   0.8153 |   1.5953
    28 |   0.1133 |   3.6161 |   0.7954 |   1.6020
    29 |   0.1078 |   3.6464 |   0.8144 |   1.6051
    30 |   0.1011 |   3.6758 |   0.8376 |   1.6092
    31 |   0.1029 |   3.6447 |   0.8292 |   1.5977
    32 |   0.0977 |   3.6897 |   0.8581 |   1.5970
    33 |   0.0992 |   3.6779 |   0.8437 |   1.6094
    34 |   0.0956 |   3.6795 |   0.8591 |   1.5987
    35 |   0.0936 |   3.7122 |   0.8669 |   1.6083
    36 |   0.0824 |   3.7545 |   0.9106 |   1.5975
    37 |   0.0804 |   3.7566 |   0.9005 |   1.5905
    38 |   0.0776 |   3.7588 |   0.9109 |   1.6059
    39 |   0.0747 |   3.7569 |   0.9290 |   1.6016
